{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4097e9c6-7f69-4e5d-8baa-9e7b36c91e75",
   "metadata": {},
   "source": [
    "# NNFS - Final Code per Chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ebb026-c107-487b-99d1-53e5c35a6065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "\n",
    "# sets random seed to 0\n",
    "# Sets dtype default to float32\n",
    "# overrides np.dot()\n",
    "#nnfs.init()\n",
    "\n",
    "from nnfs.datasets import spiral_data\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e23cb-2a39-47dc-804f-723e040d7f8c",
   "metadata": {},
   "source": [
    "## Chapter Two Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9befd32c-bbc3-448b-b783-19803df0dfb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.8  ,  1.21 ,  2.385],\n",
       "       [ 8.9  , -1.81 ,  0.2  ],\n",
       "       [ 1.41 ,  1.051,  0.026]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs= [[1.0, 2.0, 3.0, 2.5],\n",
    "                 [2.0, 5.0, -1.0, 2.0],\n",
    "                 [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "                  [0.5, -0.91, 0.26, -0.5],\n",
    "                  [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "outputs = np.dot(inputs, np.asarray(weights).T) + biases\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d3f9a3-5696-43e0-85d8-25f3d5970eae",
   "metadata": {},
   "source": [
    "## Chapter 3 Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30637373-9a4d-49e7-ae26-0901d2b8e91c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    \n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize Weights & Biases\n",
    "        # set weights to be shape (n_inputs, n_neurons) so Matrix Product can be taken easily \n",
    "        # multiply by .01 to initialize non-zero weights small enough to minimize influence on training\n",
    "        self.weights = .01 * np.random.randn(n_inputs, n_neurons)\n",
    "        # one bias per neuron, initially set to zero\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    \n",
    "    # Forward Pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) +  self.biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff35499-35ca-4297-b6bb-1d0544a2c672",
   "metadata": {},
   "source": [
    "## Chapter 4 Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a9414a-2e4d-429e-8ac7-59d10cdbe67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed3c26a-f63e-471e-968a-ba7213c0d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Softmax:\n",
    "    \n",
    "    # define forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Subtract max to help prevent overflow errors (exploding values)\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                        keepdims=True))\n",
    "        # Normalize for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                        keepdims=True)\n",
    "        self.output = probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd0e80-a567-4c32-a77c-d34b42d709da",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6d3c21-2b97-4132-a172-648466ae198a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333314, 0.33333305, 0.33333381],\n",
       "       [0.33333291, 0.3333327 , 0.33333439],\n",
       "       [0.33333279, 0.33333253, 0.33333469],\n",
       "       [0.33333334, 0.33333292, 0.33333374]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spiral Dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Initialize first hidden layer w/ 3 neurons\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Initialize ReLU Activation Function\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Initialize Second hidden layer w/ 3 neurons\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "# Initialize Softmax Activation Function\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "# Forward pass data through layer one\n",
    "dense1.forward(X)\n",
    "\n",
    "# Forward pass layer one output through ReLU Activation Function\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Forward pass output of ReLU through second dense layer\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Forward pass output of second dense layer through Softmax\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "activation2.output[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
